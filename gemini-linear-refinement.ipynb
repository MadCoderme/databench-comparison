{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10544645,"sourceType":"datasetVersion","datasetId":6524241}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip3 install google-genai databench-eval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T14:57:37.675770Z","iopub.execute_input":"2025-05-06T14:57:37.676060Z","iopub.status.idle":"2025-05-06T14:57:43.571409Z","shell.execute_reply.started":"2025-05-06T14:57:37.676030Z","shell.execute_reply":"2025-05-06T14:57:43.570418Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: google-genai in /usr/local/lib/python3.11/dist-packages (0.8.0)\nCollecting databench-eval\n  Downloading databench_eval-4.0.1-py3-none-any.whl.metadata (8.1 kB)\nRequirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.27.0)\nRequirement already satisfied: pydantic<3.0.0dev,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.11.3)\nRequirement already satisfied: requests<3.0.0dev,>=2.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.32.3)\nRequirement already satisfied: websockets<15.0dev,>=13.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (14.2)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from databench-eval) (3.5.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from databench-eval) (4.67.1)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from databench-eval) (2.2.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from databench-eval) (1.26.4)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-genai) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-genai) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-genai) (4.9)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0dev,>=2.0.0->google-genai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0dev,>=2.0.0->google-genai) (2.33.1)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0dev,>=2.0.0->google-genai) (4.13.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0dev,>=2.0.0->google-genai) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.28.1->google-genai) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.28.1->google-genai) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.28.1->google-genai) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.28.1->google-genai) (2025.1.31)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets->databench-eval) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->databench-eval) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->databench-eval) (0.3.8)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->databench-eval) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets->databench-eval) (0.70.16)\nCollecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets->databench-eval)\n  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->databench-eval) (3.11.16)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets->databench-eval) (0.30.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets->databench-eval) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets->databench-eval) (6.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->databench-eval) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->databench-eval) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->databench-eval) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->databench-eval) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->databench-eval) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->databench-eval) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->databench-eval) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->databench-eval) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->databench-eval) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->databench-eval) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->databench-eval) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->databench-eval) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->databench-eval) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->databench-eval) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->databench-eval) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->databench-eval) (1.19.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-genai) (0.6.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->databench-eval) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->databench-eval) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->databench-eval) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->databench-eval) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->databench-eval) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->databench-eval) (2024.2.0)\nDownloading databench_eval-4.0.1-py3-none-any.whl (8.4 kB)\nDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec, databench-eval\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.8.4.1 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.3.3.83 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.9.90 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.3.90 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.8.93 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.8.93 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed databench-eval-4.0.1 fsspec-2024.12.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nfrom google import genai\nfrom kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\nkey = user_secrets.get_secret(\"API_KEY\")\n\nclient = genai.Client(api_key=key)\n\nqa_df = pd.read_csv('/kaggle/input/semvaltask8/competition/test_qa.csv')\nbase_data_path = '/kaggle/input/semvaltask8/competition/'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:13:42.743017Z","iopub.execute_input":"2025-05-06T17:13:42.743370Z","iopub.status.idle":"2025-05-06T17:13:42.952637Z","shell.execute_reply.started":"2025-05-06T17:13:42.743348Z","shell.execute_reply":"2025-05-06T17:13:42.951835Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"import textwrap\nimport numpy as np \n\ndef postprocess_response(response: str, provided_dataset: str) -> str:\n    code_from_llm = response.strip()\n    if code_from_llm.startswith(\"```python\"):\n        code_from_llm = code_from_llm[len(\"```python\"):].strip()\n    if code_from_llm.startswith(\"```\"):\n         code_from_llm = code_from_llm[len(\"```\"):].strip()\n    if code_from_llm.endswith(\"```\"):\n        code_from_llm = code_from_llm[:-len(\"```\")].strip()\n\n\n    indented_code = textwrap.indent(code_from_llm, '    ')\n\n    provided_df = pd.read_parquet(base_data_path + provided_dataset + '/sample.parquet') \n    func_code_string = code_from_llm\n    try:\n\n        exec_scope = {'pd': pd, 'np': np, 'df': provided_df }\n        \n    except Exception as e:\n        print('data load error')\n        return f\"__DATA_LOAD_ERROR__: {e}\"\n    \n    try:\n        exec(func_code_string, exec_scope) # run the generated code with necessary scopes\n        answer_func = exec_scope.get('generated_answer_func')\n        if callable(answer_func):\n            try:\n                final_answer = answer_func(exec_scope['df'])\n                \n                if isinstance(final_answer, (pd.Series, pd.DataFrame)):\n                    if isinstance(final_answer, pd.Series):\n                        formatted_answer = str(final_answer.tolist())\n                    else:\n                         formatted_answer = \"__CODE_ERROR__: Returned DataFrame, expected scalar/list/bool\"\n                elif isinstance(final_answer, list):\n                    formatted_answer = str(final_answer)\n                elif isinstance(final_answer, (int, float, bool, str, np.generic)):\n                     formatted_answer = str(final_answer)\n                elif final_answer is None:\n                     formatted_answer = \"__CODE_ERROR__: Returned None\"\n                else:\n                    try:\n                        formatted_answer = str(final_answer)\n                    except Exception as fmt_e:\n                         formatted_answer = f\"__FORMAT_ERROR__: Could not convert {type(final_answer)} to string: {fmt_e}\"\n\n                if isinstance(formatted_answer, str) and \"\\n\" in formatted_answer:\n                    formatted_answer = formatted_answer.split(\"\\n\")[0]\n                print('ans: ', formatted_answer)\n                return formatted_answer\n\n            except Exception as exec_e:\n                print('exec error', exec_e)\n                return f\"__CODE_EXEC_ERROR__: {exec_e}\"\n        else:\n            print('not callable')\n            return \"__CODE_DEF_ERROR__: generated_answer_func not callable\"\n\n    except SyntaxError as syn_e:\n         return f\"__CODE_SYNTAX_ERROR__: {syn_e}\"\n    except Exception as e:\n        return f\"__EXEC_ERROR__: {e}\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T14:57:45.302221Z","iopub.execute_input":"2025-05-06T14:57:45.302478Z","iopub.status.idle":"2025-05-06T14:57:45.313357Z","shell.execute_reply.started":"2025-05-06T14:57:45.302451Z","shell.execute_reply":"2025-05-06T14:57:45.312390Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def generate_prompt_messages(row: dict, pred_format: str) -> str:\n    messages = f\"\"\"\nBased on your steps for solution, write the function below to return the answer to the question.\n\ndef generated_answer_func(df: pd.DataFrame):\n# function to answer the question: {row['question']}\n# answer format: {pred_format}\n\"\"\"\n    return messages","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T14:57:45.315542Z","iopub.execute_input":"2025-05-06T14:57:45.315954Z","iopub.status.idle":"2025-05-06T14:57:45.342287Z","shell.execute_reply.started":"2025-05-06T14:57:45.315931Z","shell.execute_reply":"2025-05-06T14:57:45.341380Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def generate_review_prompt(dataset_item: dict, previous_code: str, previous_output: str) -> list:\n    messages = f\"\"\"\nNow, review the full function below thoroughly, identify any errors, inefficiencies or areas for improvement. \nCheck if the answer format is appropriate and if it precisely what is asked in the question.\nPay attention the wording of the question.\nBased on your review, assign a score out of 100 to the solution for the question provided.\nYou need to be very harsh and mean in calculating grades, and never give full marks to ensure that the marks are authoritative.\nReturn your evaluation in json format: {{ score: number, comment: brief string }}\n\n# Question: {question}\n# Previous Code output: {previous_output}\n# Previous Code:\n{previous_code}\n\"\"\"\n    return messages","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T14:57:45.343384Z","iopub.execute_input":"2025-05-06T14:57:45.343735Z","iopub.status.idle":"2025-05-06T14:57:45.362342Z","shell.execute_reply.started":"2025-05-06T14:57:45.343683Z","shell.execute_reply":"2025-05-06T14:57:45.361450Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def generate_improve_prompt(dataset_item: dict, previous_code: str, previous_output: str, review: str) -> list:\n    messages = f\"\"\"\nBased on your review, improve and fix the previous function. If no change is needed, just return the previous code.\n\n# Question: {question}\n# Previous Code output: {previous_output}\n# Previous Code:\n{previous_code}\n# Previous code review:\n{review}\n\"\"\"\n    return messages","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T14:57:45.363426Z","iopub.execute_input":"2025-05-06T14:57:45.363806Z","iopub.status.idle":"2025-05-06T14:57:45.385651Z","shell.execute_reply.started":"2025-05-06T14:57:45.363776Z","shell.execute_reply":"2025-05-06T14:57:45.384727Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from google.genai import types\nfrom time import sleep\n\ndef gemini_model_call(message: str) -> str:\n    res = \"\"\n    try:\n        response = client.models.generate_content(\n            model=\"gemini-2.0-flash\", \n            config=types.GenerateContentConfig(\n                system_instruction=\"You are a python programmer who takes a pandas dataset, a question and returns the code to answer that question based on solely the dataset.\",\n                temperature=0.1\n            ),\n            contents=message\n        )\n        res = response.text\n        sleep(5)\n            \n    except Exception as e:\n        print(f\"Error during model generation: {e}\")\n        res = f\"__CODE_GEN_ERROR__: {e}\"\n\n    return res","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T14:57:45.386454Z","iopub.execute_input":"2025-05-06T14:57:45.386713Z","iopub.status.idle":"2025-05-06T14:57:45.404511Z","shell.execute_reply.started":"2025-05-06T14:57:45.386687Z","shell.execute_reply":"2025-05-06T14:57:45.403542Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from datasets import Dataset\nfrom tqdm.auto import tqdm\nfrom time import sleep\n\nNUM_ITERATIONS = 3\n\nqa_dataset = Dataset.from_pandas(qa_df.iloc[[144, 145, 146, 147, 148, 149]])\nprint(f\"Loaded {len(qa_dataset)} questions.\")\n\n\nfinal_results = {}\n\nfor i, data_item in enumerate(tqdm(qa_dataset, desc=\"Processing Questions\")):\n    print(data_item)\n    current_code = None\n    current_postprocess_res = None\n    last_res = None\n    error_occurred = False\n\n    question = data_item[\"question\"]\n    df_sample = pd.read_parquet(base_data_path + data_item[\"dataset\"] + '/sample.parquet') \n    columns = df_sample.columns.tolist()\n    dtypes = df_sample.dtypes.to_dict()\n    head_csv = df_sample.to_csv(index=False)\n    del df_sample \n\n    instruction = f\"\"\"# Table schema\nDataset Name: {data_item[\"dataset\"]}\nDataset columns: {columns}\nData Types: {dtypes}\nFull Dataset: {head_csv}\n# Output format:\nBoolean - if asking a yes-no, true-false question\nCell Value - if the answer should be a string value from dataframe. \nNumber - if the answer should be a numerical computed value or just a numerical value from dataframe\nList[cell values] - if asked for a list of string values from cells of the dataframe\nList[number] - if asked for a list of numerical values either computed or directly from cells\n# Rules:\n- You have access to pandas and numpy only\n- Be careful about types and do type conversion when necessary\n- Don't return any explanation or formatting outside code\n- You should write short, concise and efficient code\n- Pay attention to return type and python indentation\n- Don't return a dictionary string. Only the exact value from that dictionary which is asked\n- Don't make assumptions about the question or dataset that are not explicitly mentioned\n# Example:\ndef generated_answer_func(df: pd.DataFrame):\n    # Finds the EducationField with the fewest employees.\n\n    # Args: df: Pandas DataFrame containing employee data.\n\n    # Returns: The EducationField with the minimum number of employees.\n    education_field_counts = df['EducationField'].value_counts()\n    least_employed_field = education_field_counts.idxmin()\n    return least_employed_field\n# Question:\n{data_item['question']}\"\"\"\n    \n    chat = client.chats.create(model=\"gemini-2.5-flash-preview-04-17\", config=types.GenerateContentConfig(\n        temperature=0.1\n    ))\n    chat.send_message(instruction)\n    res = chat.send_message(\"To answer the question, describe how the answer should be provided, what should be the format and what specific information should be extracted.\")\n    pred_format = res.text\n\n    current_code = None\n    current_postprocess_res = None\n    res = None\n    for it in range(NUM_ITERATIONS):\n        if it == 0:\n            prompt = generate_prompt_messages(data_item, pred_format)\n            res = chat.send_message(prompt)\n            current_code = res.text\n            current_postprocess_res = postprocess_response(current_code, data_item['dataset'])\n\n            sleep(5)\n        else:\n            print(current_code)\n            prompt = generate_review_prompt(data_item, current_code, current_postprocess_res)\n            res = chat.send_message(prompt)\n            \n            sleep(1)\n            \n            prompt = generate_improve_prompt(data_item, current_code, current_postprocess_res, res.text)\n            res = chat.send_message(prompt)\n            current_code = res.text\n            current_postprocess_res = postprocess_response(current_code, data_item['dataset'])\n\n            sleep(4)\n    \n    \n    final_results[i] = current_postprocess_res\n    print(f\"  Finished processing Question ID: {i}. Final result stored.\")\n    print(\"-\" * 20)\n    sleep(10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T16:35:51.790623Z","iopub.execute_input":"2025-05-06T16:35:51.791215Z","iopub.status.idle":"2025-05-06T16:42:23.195348Z","shell.execute_reply.started":"2025-05-06T16:35:51.791183Z","shell.execute_reply":"2025-05-06T16:42:23.194272Z"}},"outputs":[{"name":"stdout","text":"Loaded 6 questions.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Processing Questions:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94f5d88487ff449999fe2aabfc5c74f9"}},"metadata":{}},{"name":"stdout","text":"{'question': \"Are there products from the 'Hacendado' brand in more than one country?\", 'dataset': '070_OpenFoodFacts', '__index_level_0__': 144}\nans:  True\n```python\nimport pandas as pd\nimport numpy as np\n\ndef generated_answer_func(df: pd.DataFrame):\n    # Filter the dataset to include only products where the 'brands' column contains 'Hacendado'.\n    hacendado_products = df[df['brands'].str.contains('Hacendado', na=False)]\n\n    # Extract the unique values from the 'countries_en' column for these filtered products.\n    # Drop NaN values before getting unique countries.\n    unique_countries = hacendado_products['countries_en'].dropna().unique()\n\n    # Count the number of unique countries.\n    # The answer is True if the count of unique countries is greater than 1, and False otherwise.\n    return len(unique_countries) > 1\n```\nans:  True\n```python\nimport pandas as pd\nimport numpy as np\n\ndef generated_answer_func(df: pd.DataFrame):\n    # Filter the dataset to include only products where the 'brands' column contains 'Hacendado'.\n    # Using case=False could handle variations like 'hacendado', but based on the sample,\n    # the current case-sensitive search is sufficient and slightly more efficient.\n    hacendado_products = df[df['brands'].str.contains('Hacendado', na=False)]\n\n    # Extract the unique values from the 'countries_en' column for these filtered products.\n    # The 'countries_en' column contains strings that look like lists (e.g., \"[Spain]\").\n    # We are counting the number of unique *string representations* of these country lists.\n    # This correctly identifies if products are associated with different country entries.\n    # Drop NaN values before getting unique countries.\n    unique_countries_strings = hacendado_products['countries_en'].dropna().unique()\n\n    # Count the number of unique country strings.\n    # The answer is True if the count of unique country strings is greater than 1, and False otherwise.\n    return len(unique_countries_strings) > 1\n```\nans:  True\n  Finished processing Question ID: 0. Final result stored.\n--------------------\n{'question': 'What is the most frequent brand name? Answer with a single category.', 'dataset': '070_OpenFoodFacts', '__index_level_0__': 145}\nans:  Hacendado\n```python\nimport pandas as pd\n\ndef generated_answer_func(df: pd.DataFrame):\n    # Calculate the frequency of each unique value in the 'brands' column\n    brand_counts = df['brands'].value_counts()\n\n    # Find the value with the highest frequency\n    most_frequent_brand_raw = brand_counts.idxmax()\n\n    # Clean the string by removing leading/trailing brackets and quotes\n    # First, remove brackets\n    cleaned_brand = most_frequent_brand_raw.strip('[]')\n    # Then, remove potential quotes\n    cleaned_brand = cleaned_brand.strip(\"'\").strip('\"')\n\n    return cleaned_brand\n```\nans:  Hacendado\n```python\nimport pandas as pd\n\ndef generated_answer_func(df: pd.DataFrame):\n    # Calculate the frequency of each unique value in the 'brands' column\n    brand_counts = df['brands'].value_counts()\n\n    # Find the value with the highest frequency\n    most_frequent_brand_raw = brand_counts.idxmax()\n\n    # Clean the string by removing leading/trailing brackets and quotes\n    # First, remove brackets\n    cleaned_brand = most_frequent_brand_raw.strip('[]')\n    # Then, remove potential quotes\n    cleaned_brand = cleaned_brand.strip(\"'\").strip('\"')\n\n    return cleaned_brand\n```\nans:  Hacendado\n  Finished processing Question ID: 1. Final result stored.\n--------------------\n{'question': 'Which country has the most products listed? Answer with a single category.', 'dataset': '070_OpenFoodFacts', '__index_level_0__': 146}\nans:  [Spain]\n```python\nimport pandas as pd\n\ndef generated_answer_func(df: pd.DataFrame):\n    # Count the occurrences of each country in the 'countries_en' column\n    country_counts = df['countries_en'].value_counts()\n\n    # Find the country with the highest count\n    most_common_country = country_counts.idxmax()\n\n    # Return the name of the country\n    return most_common_country\n```\nans:  [Spain]\n```python\nimport pandas as pd\n\ndef generated_answer_func(df: pd.DataFrame):\n    # Count the occurrences of each country in the 'countries_en' column\n    # value_counts() automatically excludes NaN values\n    country_counts = df['countries_en'].value_counts()\n\n    # Find the country with the highest count\n    # This will raise a ValueError if country_counts is empty (e.g., all values were NaN or df is empty)\n    # For robustness, one could add a check: if country_counts.empty: return None\n    # However, based on the typical use case and sample, assuming there's at least one valid country is reasonable.\n    most_common_country = country_counts.idxmax()\n\n    # Return the name of the country\n    return most_common_country\n```\nans:  [Spain]\n  Finished processing Question ID: 2. Final result stored.\n--------------------\n{'question': 'What is the single label associated with the most products? Answer with a single category.', 'dataset': '070_OpenFoodFacts', '__index_level_0__': 147}\nans:  Green Dot\n```python\nimport pandas as pd\nimport numpy as np\n\ndef generated_answer_func(df: pd.DataFrame):\n    # Initialize an empty list to store all individual labels\n    all_labels = []\n\n    # Iterate through the 'labels_en' column\n    for labels_str in df['labels_en']:\n        # Check if the entry is a non-empty string and not just \"[]\"\n        if isinstance(labels_str, str) and labels_str.strip() not in ['', '[]']:\n            # Remove brackets and split by comma\n            # Handle potential empty strings after splitting (e.g., \"[, Label1]\")\n            labels_list = [label.strip() for label in labels_str.strip()[1:-1].split(',') if label.strip()]\n            # Add stripped labels to the list\n            all_labels.extend(labels_list)\n\n    # If no labels were found, return None or an appropriate indicator\n    if not all_labels:\n        return None # Or handle as per requirement, maybe an empty string or raise error\n\n    # Count the occurrences of each label\n    label_counts = pd.Series(all_labels).value_counts()\n\n    # Find the label with the highest count\n    most_common_label = label_counts.idxmax()\n\n    return most_common_label\n```\nans:  Green Dot\n```python\nimport pandas as pd\nimport numpy as np\n\ndef generated_answer_func(df: pd.DataFrame):\n    # Filter out rows where labels_en is null, empty string, or '[]'\n    valid_labels_df = df[df['labels_en'].notna() & (df['labels_en'].str.strip() != '') & (df['labels_en'].str.strip() != '[]')].copy()\n\n    if valid_labels_df.empty:\n        return None # Or handle as per requirement, maybe an empty string\n\n    # Remove brackets and split the string into a list of labels\n    # Use .str[1:-1] to remove the outer brackets []\n    # Use .str.split(',') to split the string into a list\n    valid_labels_df['labels_list'] = valid_labels_df['labels_en'].str.strip().str[1:-1].str.split(',')\n\n    # Explode the list of labels into separate rows\n    all_labels_exploded = valid_labels_df.explode('labels_list')\n\n    # Strip whitespace from each label and filter out empty strings resulting from splitting\n    all_labels_cleaned = all_labels_exploded['labels_list'].str.strip()\n    all_labels_cleaned = all_labels_cleaned[all_labels_cleaned != '']\n\n    if all_labels_cleaned.empty:\n         return None # Or handle as per requirement, maybe an empty string\n\n    # Count the occurrences of each label\n    label_counts = all_labels_cleaned.value_counts()\n\n    # Find the label with the highest count\n    most_common_label = label_counts.idxmax()\n\n    return most_common_label\n```\nans:  Green Dot\n  Finished processing Question ID: 3. Final result stored.\n--------------------\n{'question': \"How many products are labeled as 'Vegan'?\", 'dataset': '070_OpenFoodFacts', '__index_level_0__': 148}\nans:  1\n```python\nimport pandas as pd\n\ndef generated_answer_func(df: pd.DataFrame):\n    # Convert the 'labels_en' column to string type to handle potential non-string values and NaNs.\n    # Then, filter the DataFrame to include only rows where 'labels_en' contains 'Vegan'.\n    # Count the number of rows in the filtered DataFrame.\n    vegan_products_count = df[df['labels_en'].astype(str).str.contains('Vegan', na=False)].shape[0]\n    return vegan_products_count\n```\nans:  1\n```python\nimport pandas as pd\n\ndef generated_answer_func(df: pd.DataFrame):\n    # Convert the 'labels_en' column to string type to handle potential non-string values and NaNs.\n    # Then, filter the DataFrame to include only rows where 'labels_en' contains 'Vegan', ignoring case.\n    # Count the number of rows in the filtered DataFrame.\n    vegan_products_count = df[df['labels_en'].astype(str).str.contains('Vegan', na=False, case=False)].shape[0]\n    return vegan_products_count\n```\nans:  1\n  Finished processing Question ID: 4. Final result stored.\n--------------------\n{'question': 'Which store has the most products listed?', 'dataset': '070_OpenFoodFacts', '__index_level_0__': 149}\nans:  []\n```python\nimport pandas as pd\nimport numpy as np\n\ndef generated_answer_func(df: pd.DataFrame):\n    # Count the occurrences of each store in the 'stores' column\n    # The 'stores' column might contain multiple stores separated by commas or be empty.\n    # We need to handle cases where a product is listed in multiple stores or no store.\n    # Let's split the string by comma and count each individual store.\n    # First, handle potential NaN values by filling with an empty string or list.\n    # Then, split the string into a list of stores.\n    # Finally, flatten the list and count the occurrences.\n\n    # Handle potential NaN values and split the string into lists of stores\n    stores_list = df['stores'].dropna().str.split(',').tolist()\n\n    # Flatten the list of lists into a single list of stores\n    flat_stores_list = [store.strip() for sublist in stores_list for store in sublist if store.strip()]\n\n    # Create a pandas Series from the flattened list to use value_counts\n    stores_series = pd.Series(flat_stores_list)\n\n    # Count the occurrences of each store\n    store_counts = stores_series.value_counts()\n\n    # Find the store with the maximum count\n    if not store_counts.empty:\n        most_common_store = store_counts.idxmax()\n        return most_common_store\n    else:\n        # Return an empty string or a specific indicator if no stores are listed\n        return \"\"\n```\nans:  []\n```python\nimport pandas as pd\nimport numpy as np\n\ndef generated_answer_func(df: pd.DataFrame):\n    # Count the occurrences of each store in the 'stores' column\n    # The 'stores' column might contain multiple stores separated by commas or be empty.\n    # We need to handle cases where a product is listed in multiple stores or no store.\n    # Split the string by comma, expand into separate columns, stack them, and count.\n\n    # Handle potential NaN values by filling with an empty string before splitting\n    # Split the 'stores' column by comma, expanding into new columns\n    # Stack the resulting columns into a single Series, dropping NaNs created by stacking empty splits\n    # Apply value_counts to count occurrences of each store\n    store_counts = df['stores'].fillna('').str.split(',', expand=True).stack().str.strip().replace('', np.nan).dropna().value_counts()\n\n    # Find the store with the maximum count\n    if not store_counts.empty:\n        most_common_store = store_counts.idxmax()\n        return most_common_store\n    else:\n        # Return an empty string if no stores are listed or all entries are empty/NaN\n        return \"\"\n```\nans:  []\n  Finished processing Question ID: 5. Final result stored.\n--------------------\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"final_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:08:19.275299Z","iopub.execute_input":"2025-05-06T17:08:19.280519Z","iopub.status.idle":"2025-05-06T17:08:19.303391Z","shell.execute_reply.started":"2025-05-06T17:08:19.280433Z","shell.execute_reply":"2025-05-06T17:08:19.301884Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"{0: 'True', 1: 'Hacendado', 2: '[Spain]', 3: 'Green Dot', 4: '1', 5: '[]'}"},"metadata":{}}],"execution_count":27},{"cell_type":"markdown","source":"###### **Evaluation:** 84.67% accuracy","metadata":{}}]}